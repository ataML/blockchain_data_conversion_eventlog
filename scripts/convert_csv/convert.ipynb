{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "\n",
    "\n",
    "#the extract function is used from: \n",
    "#https://hackersandslackers.com/extract-data-from-complex-json-python/\n",
    "\n",
    "#fields contains the keys in json file which will be extracted\n",
    "fields = [\"timestamp\",\"tx_id\",\"mspid\"]\n",
    "\n",
    "\n",
    "\n",
    "#csv_path is the path to the output file, in which the extracted data is written in csv format\n",
    "csv_path =\"data_org.csv\"\n",
    "\n",
    "file_dir=\"data\"\n",
    "\n",
    "\n",
    "def scan_files(path):\n",
    "    \n",
    "    case_id=1\n",
    "    \n",
    "    with open(csv_path,\"w\") as f:\n",
    "       \n",
    "        #writing the header for csv  \n",
    "        i = 0\n",
    "        for i in range(len(fields)):\n",
    "            f.write(fields[i] + \";\")\n",
    "        i+=1\n",
    "      #  f.write(fields[i]+\"\\n\")\n",
    "        f.write(\"activity_name;case_id\\n\")\n",
    "        f.close()\n",
    "    dir_dict={}\n",
    "    \n",
    "    \n",
    "    #all files in the directory are scanned, then the name, and extension of each file is extracted,\n",
    "    #a dictionary is created in which keys are the index of each file, and the values are DirEntry of files\n",
    "    #finaly in ordered_directory_dict all files are sorted based on their indecies\n",
    "    for file_path in os.scandir(path):\n",
    "        \n",
    "        if file_path.is_file():\n",
    "            base_name= os.path.basename(file_path)\n",
    "            name, extension = os.path.splitext(base_name)\n",
    "\n",
    "            if(extension ==\".json\"):\n",
    "                dir_dict[int(name)]= file_path\n",
    "    ordered_directory_dict=collections.OrderedDict(sorted(dir_dict.items()))\n",
    "        \n",
    "   \n",
    "    #looping through all json files \n",
    "    for _ , file_path in ordered_directory_dict.items():\n",
    "        \n",
    " \n",
    "        file_values=[]\n",
    "    \n",
    "        #reading one file\n",
    "        with open(file_path) as json_file:\n",
    "            \n",
    "            json_data = json.load(json_file)\n",
    "            \n",
    "\n",
    "            for field in fields:\n",
    "                \n",
    "                field_values=[]\n",
    "                res = json_extract(json_data,field)\n",
    "\n",
    "                for item in res:\n",
    "                    field_values.append(item)\n",
    "                file_values.append(field_values)\n",
    "                \n",
    "            #we list get all keys which named \"key\"\n",
    "            #within these keys we extract the function names\n",
    "            function_names=[]\n",
    "            keys= json_extract(json_data,\"key\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            for name in keys:\n",
    "                \n",
    "                if \"functionname\" in name:\n",
    "                 #   print(\"HHHH \")\n",
    "                 #   print(name)\n",
    "                    #we store function names in the form function_XXX,\n",
    "                    #so we split the name by \"_\" to get the actual function name\n",
    "                    function_names.append(name.split(\"_\")[1])\n",
    "        #    print(function_names)   \n",
    "            file_values.append(function_names)\n",
    "            json_file.close()\n",
    "\n",
    "        case_id=csv_write(fields,file_values,csv_path,case_id)\n",
    "                \n",
    "            \n",
    "\n",
    "def csv_write(fields, data,path,case_id):\n",
    "    \n",
    "   # print(\"len is ::   \")\n",
    "   # print(data[1])\n",
    "    \n",
    "    count=0\n",
    "    with open(path,\"a\") as f:\n",
    "        \n",
    "        i = 0\n",
    "\n",
    "        \n",
    "        for i in range(len(data[0])):\n",
    "\n",
    "            for j in range(len(data)):\n",
    "                                    \n",
    "                if (i < len(data[j])):\n",
    "                    f.write(\"\\\"%s\\\"\" % data[j][i])\n",
    "                    \n",
    "                    if(data[j][i]==\"createCar\"):\n",
    "                        case_id+=1\n",
    "                        count=1\n",
    "                else:\n",
    "                    f.write(\"\\\"\\\"\")\n",
    "                if(j < len(data)-1):\n",
    "                    f.write(\";\")\n",
    "            f.write(\";\")\n",
    "            f.write(str(case_id))\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "      #  i+=1\n",
    "      #  f.write(\"%s\\n\" % data[i])\n",
    "        if(count == 0):\n",
    "            case_id+=1\n",
    "        \n",
    "        f.close()\n",
    "        return case_id\n",
    "    \n",
    "    \n",
    "def json_extract(obj, key):\n",
    "    \"\"\"Recursively fetch values from nested JSON.\"\"\"\n",
    "    arr = []\n",
    "\n",
    "    def extract(obj, arr, key):\n",
    "        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            for k, v in obj.items():\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    extract(v, arr, key)\n",
    "                elif k == key:\n",
    "                    arr.append(v)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                extract(item, arr, key)\n",
    "        return arr\n",
    "\n",
    "    values = extract(obj, arr, key)\n",
    "    return values\n",
    "\n",
    "\n",
    "scan_files(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
